/** Default temperature setting for LLM requests */
export const DEFAULT_TEMPERATURE = 0.3

/** Maximum tokens for phrase generation requests */
export const PHRASE_GENERATION_MAX_TOKENS = 2000

/** Maximum tokens for kanji lookup requests */
export const KANJI_LOOKUP_MAX_TOKENS = 1500

/** Default provider when none specified */
export const DEFAULT_PROVIDER = 'OpenAI'
